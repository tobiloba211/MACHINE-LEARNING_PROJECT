{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fdaeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "To incorporate the provided speech recognition functionality into the **chatbot code**, we'll follow these steps:\n",
    "\n",
    "1. Add the **speech recognition** features so that the user can either speak or type their question.\n",
    "2. Update the chatbot to **transcribe speech** using the microphone or an audio file, and pass the transcribed text to the chatbot system.\n",
    "3. Ensure the chatbot processes both types of input (typed or transcribed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0927332a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wonderland_voice_chatbot.py creation executed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create the file wonderland_voice_chatbot.py in write mode\n",
    "with open(\"wonderland_voice_chatbot.py\", \"w\") as file:\n",
    "    # Writing the Streamlit code into the file\n",
    "    file.write('''\n",
    "    \n",
    "##### Chatbot with Speech Recognition #####\n",
    "\n",
    "# Import necessary libraries\n",
    "import nltk  # Natural Language Toolkit for text processing\n",
    "import streamlit as st  # Streamlit for building the web app interface\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize  # Tokenizing sentences and words\n",
    "from nltk.corpus import stopwords  # Stopwords list to remove common words like \"the\", \"and\"\n",
    "from nltk.stem import WordNetLemmatizer  # Lemmatizer for converting words to their root form\n",
    "import string  # String for handling punctuation\n",
    "import speech_recognition as sr  # Speech recognition library for converting speech to text\n",
    "\n",
    "# Initialize the speech recognition engine\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Load stopwords (common words to be removed) and initialize the lemmatizer (for root word extraction)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Step 1: Function to transcribe live speech input using the microphone\n",
    "def transcribe_speech():\n",
    "    try:\n",
    "        with sr.Microphone() as source:  # Use the microphone as the audio source\n",
    "            st.info(\"Speak now... Please speak clearly!\")\n",
    "            audio = recognizer.listen(source)  # Capture the speech from the microphone\n",
    "            st.info(\"Transcribing speech...\")\n",
    "            return recognizer.recognize_google(audio)  # Transcribe speech to text using Google API\n",
    "    except sr.UnknownValueError:  # Error handling if speech is not recognized\n",
    "        return \"Sorry, I couldn't understand that.\"\n",
    "    except sr.RequestError:  # Error handling for API unavailability\n",
    "        return \"API unavailable or unresponsive.\"\n",
    "    except Exception as e:  # Generic error handling\n",
    "        return f\"An error occurred: {str(e)}\"\n",
    "\n",
    "# Step 2: Function to transcribe an audio file input\n",
    "def transcribe_audio_file(file_path):\n",
    "    try:\n",
    "        with sr.AudioFile(file_path) as source:  # Use the uploaded audio file as the source\n",
    "            audio = recognizer.record(source)  # Record the entire file\n",
    "            st.info(\"Transcribing audio file...\")\n",
    "            return recognizer.recognize_google(audio)  # Transcribe the audio to text using Google API\n",
    "    except sr.UnknownValueError:  # Error handling for unrecognized audio\n",
    "        return \"Sorry, I couldn't understand the audio.\"\n",
    "    except sr.RequestError:  # Error handling if the API is unresponsive\n",
    "        return \"API unavailable or unresponsive.\"\n",
    "    except Exception as e:  # Generic error handling\n",
    "        return f\"An error occurred: {str(e)}\"\n",
    "    \n",
    "# Text preprocessing function: tokenizes, removes stopwords, lemmatizes, and removes punctuation\n",
    "def preprocess(sentence):\n",
    "    words = word_tokenize(sentence.lower())  # Tokenize the sentence into words and convert to lowercase\n",
    "    words = [word for word in words if word not in stop_words and word not in string.punctuation]  # Remove stopwords and punctuation\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]  # Lemmatize the words to their root forms\n",
    "    return words\n",
    "\n",
    "# Function to load and preprocess the text file (Alice in Wonderland)\n",
    "def load_text():\n",
    "    try:\n",
    "        file_path = r'C:\\\\Users\\\\pc\\\\Desktop\\\\B-older\\\\Data and Stuff\\\\GMC\\\\ML GMC\\\\alice_in_wonderland.txt'  # Path to the text file\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return file.read().replace('\\\\n', ' ')  # Load and return the text, replacing line breaks with spaces\n",
    "    except FileNotFoundError:  # Error handling if the file is not found\n",
    "        st.error(\"Text file not found.\")\n",
    "        return \"\"\n",
    "\n",
    "# Tokenizes the text into sentences and preprocesses each sentence\n",
    "def prepare_corpus(text):\n",
    "    sentences = sent_tokenize(text)  # Split the text into individual sentences\n",
    "    return [preprocess(sentence) for sentence in sentences]  # Preprocess each sentence\n",
    "\n",
    "# Function to calculate Jaccard similarity between two sets of words\n",
    "def jaccard_similarity(query, sentence):\n",
    "    query_set = set(query)  # Convert the query to a set of unique words\n",
    "    sentence_set = set(sentence)  # Convert the sentence to a set of unique words\n",
    "    if len(query_set.union(sentence_set)) == 0:  # If both sets are empty\n",
    "        return 0\n",
    "    return len(query_set.intersection(sentence_set)) / len(query_set.union(sentence_set))  # Calculate Jaccard similarity\n",
    "\n",
    "# Function to find the most relevant sentence based on Jaccard similarity\n",
    "def get_most_relevant_sentence(query, corpus, original_sentences):\n",
    "    query = preprocess(query)  # Preprocess the user query\n",
    "    max_similarity = 0  # Initialize maximum similarity\n",
    "    best_sentence = \"I couldn't find a relevant answer.\"  # Default response if no relevant sentence is found\n",
    "    for i, sentence in enumerate(corpus):  # Iterate through each sentence in the corpus\n",
    "        similarity = jaccard_similarity(query, sentence)  # Calculate similarity between query and the current sentence\n",
    "        if similarity > max_similarity:  # If the current sentence has higher similarity than the previous max\n",
    "            max_similarity = similarity\n",
    "            best_sentence = original_sentences[i]  # Set the best sentence to the original sentence with the highest similarity\n",
    "    return best_sentence\n",
    "\n",
    "# Main function to create the Streamlit interface for the chatbot\n",
    "def main():\n",
    "    st.title(\"Wonderland's Novice Chatbot with Voice Input\")  # App title\n",
    "    st.write(\"Ask me anything related to Alice in Wonderland! You can either speak, upload an audio file, or type your question.\")  # App description\n",
    "\n",
    "    # Suggestions for users to try asking\n",
    "    with st.expander(\"Click me for suggestions\"):\n",
    "        st.write(\"\"\"\n",
    "        1. Who does Alice meet first in Wonderland?\n",
    "        2. What is the Cheshire Cat's famous line?\n",
    "        3. How does Alice enter Wonderland?\n",
    "        4. What is the Queen of Hearts known for?\n",
    "        \"\"\")\n",
    "\n",
    "    # Load the text of Alice in Wonderland and prepare the corpus\n",
    "    text = load_text()  # Load the text\n",
    "    if text:\n",
    "        corpus = prepare_corpus(text)  # Preprocess the corpus (tokenized and cleaned)\n",
    "        original_sentences = sent_tokenize(text)  # Store the original sentences\n",
    "\n",
    "        # User input options: live speech, file upload, or text input\n",
    "        speech_input = st.button(\"Speak your question\")  # Button for live speech input\n",
    "        file_input = st.file_uploader(\"Upload an audio file:\", type=['wav', 'mp3'])  # Upload an audio file\n",
    "        user_input = st.text_input(\"Or type your question:\")  # Text input option\n",
    "\n",
    "        # Handle live speech input\n",
    "        if speech_input:\n",
    "            user_input = transcribe_speech()  # Transcribe the speech to text\n",
    "            st.write(f\"Transcribed Text: {user_input}\")  # Display the transcribed text\n",
    "\n",
    "        # Handle audio file input\n",
    "        if file_input:\n",
    "            user_input = transcribe_audio_file(file_input)  # Transcribe the audio file to text\n",
    "            st.write(f\"Transcribed Audio File: {user_input}\")  # Display the transcribed text\n",
    "\n",
    "        # Process the user input if available\n",
    "        if user_input:\n",
    "            response = get_most_relevant_sentence(user_input, corpus, original_sentences)  # Get the most relevant sentence\n",
    "            st.write(f\"Chatbot: {response}\")  # Display the chatbot's response\n",
    "        else:\n",
    "            st.write(\"Please ask a question by speaking, uploading a file, or typing.\")  # Prompt the user to ask a question\n",
    "\n",
    "# Run the Streamlit app\n",
    "if __name__ == \"__main__\":  # If the script is being run directly\n",
    "    main()  # Run the main function\n",
    "    ''')\n",
    "\n",
    "print(\"wonderland_voice_chatbot.py creation executed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1192620",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3447823841.py, line 51)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 51\u001b[1;36m\u001b[0m\n\u001b[1;33m    words = [word for word in w ords if word not in stop_words and word not in string.punctuation]  # Remove stopwords and punctuation\u001b[0m\n\u001b[1;37m                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "##### Chatbot with Speech Recognition #####\n",
    "\n",
    "# Import necessary libraries\n",
    "import nltk  # Natural Language Toolkit for text processing\n",
    "import streamlit as st  # Streamlit for building the web app interface\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize  # Tokenizing sentences and words\n",
    "from nltk.corpus import stopwords  # Stopwords list to remove common words like \"the\", \"and\"\n",
    "from nltk.stem import WordNetLemmatizer  # Lemmatizer for converting words to their root form\n",
    "import string  # String for handling punctuation\n",
    "import speech_recognition as sr  # Speech recognition library for converting speech to text\n",
    "\n",
    "# Initialize the speech recognition engine\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Load stopwords (common words to be removed) and initialize the lemmatizer (for root word extraction)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Step 1: Function to transcribe live speech input using the microphone\n",
    "def transcribe_speech():\n",
    "    try:\n",
    "        with sr.Microphone() as source:  # Use the microphone as the audio source\n",
    "            st.info(\"Speak now... Please speak clearly!\")\n",
    "            audio = recognizer.listen(source)  # Capture the speech from the microphone\n",
    "            st.info(\"Transcribing speech...\")\n",
    "            return recognizer.recognize_google(audio)  # Transcribe speech to text using Google API\n",
    "    except sr.UnknownValueError:  # Error handling if speech is not recognized\n",
    "        return \"Sorry, I couldn't understand that.\"\n",
    "    except sr.RequestError:  # Error handling for API unavailability\n",
    "        return \"API unavailable or unresponsive.\"\n",
    "    except Exception as e:  # Generic error handling\n",
    "        return f\"An error occurred: {str(e)}\"\n",
    "\n",
    "# Step 2: Function to transcribe an audio file input\n",
    "def transcribe_audio_file(file_path):\n",
    "    try:\n",
    "        with sr.AudioFile(file_path) as source:  # Use the uploaded audio file as the source\n",
    "            audio = recognizer.record(source)  # Record the entire file\n",
    "            st.info(\"Transcribing audio file...\")\n",
    "            return recognizer.recognize_google(audio)  # Transcribe the audio to text using Google API\n",
    "    except sr.UnknownValueError:  # Error handling for unrecognized audio\n",
    "        return \"Sorry, I couldn't understand the audio.\"\n",
    "    except sr.RequestError:  # Error handling if the API is unresponsive\n",
    "        return \"API unavailable or unresponsive.\"\n",
    "    except Exception as e:  # Generic error handling\n",
    "        return f\"An error occurred: {str(e)}\"\n",
    "    \n",
    "# Text preprocessing function: tokenizes, removes stopwords, lemmatizes, and removes punctuation\n",
    "def preprocess(sentence):\n",
    "    words = word_tokenize(sentence.lower())  # Tokenize the sentence into words and convert to lowercase\n",
    "    words = [word for word in w ords if word not in stop_words and word not in string.punctuation]  # Remove stopwords and punctuation\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]  # Lemmatize the words to their root forms\n",
    "    return words\n",
    "\n",
    "# Function to load and preprocess the text file (Alice in Wonderland)\n",
    "def load_text():\n",
    "    try:\n",
    "        file_path = r'C:\\Users\\pc\\Desktop\\B-older\\Data and Stuff\\GMC\\ML GMC\\alice_in_wonderland.txt'  # Path to the text file\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return file.read().replace('\\n', ' ')  # Load and return the text, replacing line breaks with spaces\n",
    "    except FileNotFoundError:  # Error handling if the file is not found\n",
    "        st.error(\"Text file not found.\")\n",
    "        return \"\"\n",
    "\n",
    "# Tokenizes the text into sentences and preprocesses each sentence\n",
    "def prepare_corpus(text):\n",
    "    sentences = sent_tokenize(text)  # Split the text into individual sentences\n",
    "    return [preprocess(sentence) for sentence in sentences]  # Preprocess each sentence\n",
    "\n",
    "# Function to calculate Jaccard similarity between two sets of words\n",
    "def jaccard_similarity(query, sentence):\n",
    "    query_set = set(query)  # Convert the query to a set of unique words\n",
    "    sentence_set = set(sentence)  # Convert the sentence to a set of unique words\n",
    "    if len(query_set.union(sentence_set)) == 0:  # If both sets are empty\n",
    "        return 0\n",
    "    return len(query_set.intersection(sentence_set)) / len(query_set.union(sentence_set))  # Calculate Jaccard similarity\n",
    "\n",
    "# Function to find the most relevant sentence based on Jaccard similarity\n",
    "def get_most_relevant_sentence(query, corpus, original_sentences):\n",
    "    query = preprocess(query)  # Preprocess the user query\n",
    "    max_similarity = 0  # Initialize maximum similarity\n",
    "    best_sentence = \"I couldn't find a relevant answer.\"  # Default response if no relevant sentence is found\n",
    "    for i, sentence in enumerate(corpus):  # Iterate through each sentence in the corpus\n",
    "        similarity = jaccard_similarity(query, sentence)  # Calculate similarity between query and the current sentence\n",
    "        if similarity > max_similarity:  # If the current sentence has higher similarity than the previous max\n",
    "            max_similarity = similarity\n",
    "            best_sentence = original_sentences[i]  # Set the best sentence to the original sentence with the highest similarity\n",
    "    return best_sentence\n",
    "\n",
    "# Main function to create the Streamlit interface for the chatbot\n",
    "def main():\n",
    "    st.title(\"Wonderland's Novice Chatbot with Voice Input\")  # App title\n",
    "    st.write(\"Ask me anything related to Alice in Wonderland! You can either speak, upload an audio file, or type your question.\")  # App description\n",
    "\n",
    "    # Suggestions for users to try asking\n",
    "    with st.expander(\"Click me for suggestions\"):\n",
    "        st.write(\"\"\"\n",
    "        1. Who does Alice meet first in Wonderland?\n",
    "        2. What is the Cheshire Cat's famous line?\n",
    "        3. How does Alice enter Wonderland?\n",
    "        4. What is the Queen of Hearts known for?\n",
    "        \"\"\")\n",
    "\n",
    "    # Load the text of Alice in Wonderland and prepare the corpus\n",
    "    text = load_text()  # Load the text\n",
    "    if text:\n",
    "        corpus = prepare_corpus(text)  # Preprocess the corpus (tokenized and cleaned)\n",
    "        original_sentences = sent_tokenize(text)  # Store the original sentences\n",
    "\n",
    "        # User input options: live speech, file upload, or text input\n",
    "        speech_input = st.button(\"Speak your question\")  # Button for live speech input\n",
    "        file_input = st.file_uploader(\"Upload an audio file:\", type=['wav', 'mp3'])  # Upload an audio file\n",
    "        user_input = st.text_input(\"Or type your question:\")  # Text input option\n",
    "\n",
    "        # Handle live speech input\n",
    "        if speech_input:\n",
    "            user_input = transcribe_speech()  # Transcribe the speech to text\n",
    "            st.write(f\"Transcribed Text: {user_input}\")  # Display the transcribed text\n",
    "\n",
    "        # Handle audio file input\n",
    "        if file_input:\n",
    "            user_input = transcribe_audio_file(file_input)  # Transcribe the audio file to text\n",
    "            st.write(f\"Transcribed Audio File: {user_input}\")  # Display the transcribed text\n",
    "\n",
    "        # Process the user input if available\n",
    "        if user_input:\n",
    "            response = get_most_relevant_sentence(user_input, corpus, original_sentences)  # Get the most relevant sentence\n",
    "            st.write(f\"Chatbot: {response}\")  # Display the chatbot's response\n",
    "        else:\n",
    "            st.write(\"Please ask a question by speaking, uploading a file, or typing.\")  # Prompt the user to ask a question\n",
    "\n",
    "# Run the Streamlit app\n",
    "if __name__ == \"__main__\":  # If the script is being run directly\n",
    "    main()  # Run the main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e32ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Running the App:\n",
    "- **Live Speech**: Press the \"Speak your question\" button to record audio and have it transcribed.\n",
    "- **Audio File**: Upload an audio file using the file uploader.\n",
    "- **Text Input**: Type your question in the text input field.\n",
    "\n",
    "The chatbot will respond based on the processed input, and you can continue interacting with it through any of the available options."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
